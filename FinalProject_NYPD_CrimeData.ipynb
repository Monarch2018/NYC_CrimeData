{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting “Successful” Criminal Activity in New York City**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is disigned to predict whether crimes commited in NYC will be “successful” or “unsuccessful.” Multiple classification models are tested to determine which has the highest accuracy when used on the NYPD Complaint Data dataset, which includes all valid felony, misdemeanor, and violation crimes reported to the New York City Police Department (NYPD) in the first quarter of 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "df = pd.read_csv('NYPD_Complaint_Data_Current_YTD.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data prepocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRM_ATPT_CPTD_CD</th>\n",
       "      <th>LAW_CAT_CD</th>\n",
       "      <th>OFNS_DESC</th>\n",
       "      <th>PD_DESC</th>\n",
       "      <th>PREM_TYP_DESC</th>\n",
       "      <th>SUSP_AGE_GROUP</th>\n",
       "      <th>SUSP_RACE</th>\n",
       "      <th>SUSP_SEX</th>\n",
       "      <th>VIC_AGE_GROUP</th>\n",
       "      <th>VIC_RACE</th>\n",
       "      <th>VIC_SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>MISDEMEANOR</td>\n",
       "      <td>DANGEROUS WEAPONS</td>\n",
       "      <td>WEAPONS, POSSESSION, ETC</td>\n",
       "      <td>STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>FELONY</td>\n",
       "      <td>RAPE</td>\n",
       "      <td>RAPE 2</td>\n",
       "      <td>RESIDENCE - PUBLIC HOUSING</td>\n",
       "      <td>18-24</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>M</td>\n",
       "      <td>&lt;18</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>MISDEMEANOR</td>\n",
       "      <td>OFF. AGNST PUB ORD SENSBLTY &amp;</td>\n",
       "      <td>AGGRAVATED HARASSMENT 2</td>\n",
       "      <td>RESIDENCE-HOUSE</td>\n",
       "      <td>25-44</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>M</td>\n",
       "      <td>18-24</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>FELONY</td>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>ROBBERY,DELIVERY PERSON</td>\n",
       "      <td>RESIDENCE - APT. HOUSE</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>M</td>\n",
       "      <td>25-44</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>VIOLATION</td>\n",
       "      <td>HARRASSMENT 2</td>\n",
       "      <td>HARASSMENT,SUBD 3,4,5</td>\n",
       "      <td>RESIDENCE - PUBLIC HOUSING</td>\n",
       "      <td>45-64</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>F</td>\n",
       "      <td>25-44</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CRM_ATPT_CPTD_CD   LAW_CAT_CD                      OFNS_DESC  \\\n",
       "0        COMPLETED  MISDEMEANOR              DANGEROUS WEAPONS   \n",
       "1        COMPLETED       FELONY                           RAPE   \n",
       "2        COMPLETED  MISDEMEANOR  OFF. AGNST PUB ORD SENSBLTY &   \n",
       "3        COMPLETED       FELONY                        ROBBERY   \n",
       "4        COMPLETED    VIOLATION                  HARRASSMENT 2   \n",
       "\n",
       "                    PD_DESC               PREM_TYP_DESC SUSP_AGE_GROUP  \\\n",
       "0  WEAPONS, POSSESSION, ETC                      STREET            NaN   \n",
       "1                    RAPE 2  RESIDENCE - PUBLIC HOUSING          18-24   \n",
       "2   AGGRAVATED HARASSMENT 2             RESIDENCE-HOUSE          25-44   \n",
       "3   ROBBERY,DELIVERY PERSON      RESIDENCE - APT. HOUSE        UNKNOWN   \n",
       "4     HARASSMENT,SUBD 3,4,5  RESIDENCE - PUBLIC HOUSING          45-64   \n",
       "\n",
       "        SUSP_RACE SUSP_SEX VIC_AGE_GROUP        VIC_RACE VIC_SEX  \n",
       "0             NaN      NaN       UNKNOWN         UNKNOWN       E  \n",
       "1         UNKNOWN        M           <18           BLACK       F  \n",
       "2           BLACK        M         18-24           BLACK       F  \n",
       "3  WHITE HISPANIC        M         25-44  WHITE HISPANIC       M  \n",
       "4  WHITE HISPANIC        F         25-44           BLACK       F  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_remove = ['CMPLNT_NUM', 'ADDR_PCT_CD', 'BORO_NM', 'CMPLNT_FR_DT', 'CMPLNT_FR_TM', 'CMPLNT_TO_DT', \n",
    "                  'CMPLNT_TO_TM', 'HADEVELOPT', 'HOUSING_PSA', 'JURISDICTION_CODE', 'JURIS_DESC', 'KY_CD', \n",
    "                  'LOC_OF_OCCUR_DESC', 'PARKS_NM', 'PATROL_BORO', 'PD_CD', \n",
    "                  'RPT_DT', 'STATION_NAME', 'TRANSIT_DISTRICT', 'X_COORD_CD',\n",
    "                  'Y_COORD_CD', 'Latitude', 'Longitude', 'Lat_Lon']\n",
    "\n",
    "df = df.drop(columns_remove, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing rows with missing values: 109543\n",
      "Number of rows after removing rows with missing values: 31597\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace UNKNOWN and erroneous values with nulls\n",
    "df.replace('UNKNOWN', np.NaN, inplace=True)\n",
    "df.replace('E', np.NaN, inplace=True)\n",
    "df.replace('D', np.NaN, inplace=True)\n",
    "df.replace('U', np.NaN, inplace=True)\n",
    "\n",
    "print('Number of rows before removing rows with missing values: ' + str(df.shape[0]))\n",
    "\n",
    "# Remove rows with null values\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "print('Number of rows after removing rows with missing values: ' + str(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Get the feature and target vectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (31597, 10)\n",
      "y shape: (31597,)\n"
     ]
    }
   ],
   "source": [
    "# Get the feature vector\n",
    "X = df.drop('CRM_ATPT_CPTD_CD', axis = 1)\n",
    "\n",
    "# Get the target vector\n",
    "y = df['CRM_ATPT_CPTD_CD']\n",
    "\n",
    "print('X shape: ' + str(X.shape))\n",
    "print('y shape: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the target vector (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom encoder for the feature vector (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This custom encoder will encode all features in the feature vector, since LabelEncoder is only capable of encoding 1-d arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    \n",
    "    def __init__(self, columns=None):\n",
    "        # Array of column names to encode\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Transforms columns of X specified in self.columns using LabelEncoder()\n",
    "        # If no columns specified, transforms all columns in X\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname, col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the feature vector (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MultiColumnLabelEncoder().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Divide data into training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y train shape: (array([0, 1]), array([  345, 21772]))\n",
      "y test shape: (array([0, 1]), array([ 148, 9332]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Randomly choose 30% of the data for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "# Show the shape of the data\n",
    "print('y train shape: ' + str(np.unique(y_train, return_counts=True)))\n",
    "print('y test shape: ' + str(np.unique(y_test, return_counts=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Model Selection: LR, MLP, DT, RF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of classifiers:\n",
    "- Logistic Regression\n",
    "- Multi-Layer Perceptron\n",
    "- Decistion Tree\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key is the classifier acronym and the value is the classifier\n",
    "the value is the classifier (with random_state=0)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfs = {'lr': LogisticRegression(random_state=0),\n",
    "        'mlp': MLPClassifier(random_state=0),\n",
    "        'dt': DecisionTreeClassifier(random_state=0),\n",
    "        'rf': RandomForestClassifier(random_state=0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key is the classifier acronym and the value is the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe_clfs = {}\n",
    "\n",
    "for name, clf in clfs.items():\n",
    "    pipe_clfs[name] = Pipeline([('StandardScaler', StandardScaler()), ('clf', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of parameter grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key is the classifier acronym and the value is the parameter grid of the classifier\n",
    "param_grids = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create parameter grids for each classifier and set values for hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set C range\n",
    "C_range = [10 ** i for i in range(-4, 5)]\n",
    "\n",
    "# Create parameter grid for Logistic Regression\n",
    "# Hyper parameters being tunes are multi_class, solver, C\n",
    "param_grid = [{'clf__multi_class': ['ovr'], \n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'clf__C': C_range},\n",
    "              {'clf__multi_class': ['multinomial'],\n",
    "               'clf__solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'clf__C': C_range}]\n",
    "param_grids['lr'] = param_grid\n",
    "\n",
    "# Create parameter grid for Multi-Layer Perceptron\n",
    "# Hyper parameters being tunes are hidden_layer_sizes, activation\n",
    "param_grid = [{'clf__hidden_layer_sizes': [10, 100, 200, 500],\n",
    "               'clf__activation': ['identity', 'logistic', 'tanh', 'relu']}]\n",
    "param_grids['mlp'] = param_grid\n",
    "\n",
    "# Create parameter grid for Decision Tree\n",
    "# Hyper parameters being tunes are min_samples_split, min_samples_leaf\n",
    "param_grid = [{'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "param_grids['dt'] = param_grid\n",
    "\n",
    "# Create parameter grid for Random Forest\n",
    "# Hyper parameters being tunes are n_estimators, min_samples_split, min_samples_leaf\n",
    "param_grid = [{'clf__n_estimators': [2, 10, 30],\n",
    "               'clf__min_samples_split': [2, 10, 30],\n",
    "               'clf__min_samples_leaf': [1, 10, 30]}]\n",
    "param_grids['rf'] = param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune hyper parameters using GridSearchCV in conjunction with StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This may take up to an hour given the number of samples in X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# List of [best_score_, best_params_, best_estimator_]\n",
    "best_score_param_estimators = []\n",
    "\n",
    "# Use GridSearchCV on each classifier\n",
    "for name in pipe_clfs.keys():\n",
    "    gs = GridSearchCV(estimator=pipe_clfs[name],\n",
    "                      param_grid=param_grids[name],\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=1,\n",
    "                      cv=StratifiedKFold(n_splits=20, shuffle=True, random_state=0))\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Update best_score_param_estimators\n",
    "    best_score_param_estimators.append([gs.best_score_, gs.best_params_, gs.best_estimator_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print best score and parameters for each classifier (estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.985034136636976, {'clf__min_samples_leaf': 1, 'clf__min_samples_split': 30, 'clf__n_estimators': 30}, <class 'sklearn.ensemble.forest.RandomForestClassifier'>]\n",
      "\n",
      "[0.9848080661934259, {'clf__min_samples_leaf': 10, 'clf__min_samples_split': 30}, <class 'sklearn.tree.tree.DecisionTreeClassifier'>]\n",
      "\n",
      "[0.9844011393950355, {'clf__C': 0.0001, 'clf__multi_class': 'ovr', 'clf__solver': 'newton-cg'}, <class 'sklearn.linear_model.logistic.LogisticRegression'>]\n",
      "\n",
      "[0.9844011393950355, {'clf__activation': 'identity', 'clf__hidden_layer_sizes': 10}, <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort best_score_param_estimators in ascending order of best_score_\n",
    "best_score_param_estimators = sorted(best_score_param_estimators, key=lambda x : x[0], reverse=True)\n",
    "\n",
    "# For each [best_score_, best_params_, best_estimator_], Print out [best_score_, best_params_, best_estimator_], \n",
    "# where best_estimator_ is a pipeline\n",
    "for best_score_param_estimator in best_score_param_estimators:\n",
    "    print([best_score_param_estimator[0], best_score_param_estimator[1], \n",
    "           type(best_score_param_estimator[2].named_steps['clf'])], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the highest scoring classifier and associated parameters on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "\n",
      "Accuracy: 0.9850210970464135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "y_pred = best_score_param_estimators[0][2].predict(X_test)\n",
    "\n",
    "print('Classifier:', end=' ')\n",
    "print(type(best_score_param_estimators[0][2].named_steps['clf']), end='\\n\\n')\n",
    "print('Accuracy:', end=' ')\n",
    "print(precision_recall_fscore_support(y_pred, y_test, average='micro')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Model Selection: Deep Neural Network with Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22117/22117 [==============================] - 3s 114us/step - loss: 0.1273 - acc: 0.9768\n",
      "Epoch 2/5\n",
      "22117/22117 [==============================] - 2s 98us/step - loss: 0.0760 - acc: 0.9844\n",
      "Epoch 3/5\n",
      "22117/22117 [==============================] - 2s 98us/step - loss: 0.0730 - acc: 0.9844\n",
      "Epoch 4/5\n",
      "22117/22117 [==============================] - 2s 97us/step - loss: 0.0710 - acc: 0.9844\n",
      "Epoch 5/5\n",
      "22117/22117 [==============================] - 2s 100us/step - loss: 0.0715 - acc: 0.9844\n",
      "9480/9480 [==============================] - 0s 17us/step\n",
      "\n",
      "acc: 98.44%\n"
     ]
    }
   ],
   "source": [
    "# NOTE: must pip install keras and tensorflow\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit model to training data\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=10)\n",
    "\n",
    "# Evaluate model on test data\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Conclusion**\n",
    "After testing the data on multiple models including Logistic Regression, Multi-Layer Perceptron, Decistion Tree, Random Forest, and Deep Neural Network, it was found that Random Forest had the best performance, being able to predict whether crimes in NYC will be successful or unsuccessful with an accuracy of 0.99."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
